[DEFAULT]
# Enable Ceph in the components [y/n]
# Default values: enable Cinder only
set_glance = y
set_cinder = n
set_cinder_backup = n
set_nova = n 

# The owner of the Openstack setup
user = 

# The amount of placement groups in the pools (depends on the number of Ceph's OSD's)
# Default value: 512
ceph_pool_pg = 512 

# Path for the Ceph configuration file in the hosts
# Default value: /etc/ceph/ceph.conf
ceph_conf_file_path = /etc/ceph/ceph.conf

# Names of the hosts sections
host_names= host-a

# uuid used by Cinder/Nova for libvirt authentication with Ceph
uuid = 

# Ceph client packages
# Default value: ceph-common, python-ceph
ceph_packages = ceph-common, python-ceph

[host-a]

# FQDN / IP address of the host
hostname =

# The host's role.
# Options: ceph, cinder, cinder-backup, glance, nova
role =

# User to login with to the host (must have administrative privileges)
username =

# The user's password
password =

[GLANCE]

conf_file = /etc/glance/glance-api.conf
show_image_direct_url = true
stores_section = glance_store
store = rbd
stores = glance.store.filesystem.Store, glance.store.http.Store, glance.store.rbd.Store
rbd_store_chunk_size = 8
enable_v2_api = True
enable_v1_api = True

[CINDER]
conf_file = /etc/cinder/cinder.conf
backend_name = ceph
glance_client_api = 2
driver = cinder.volume.drivers.rbd.RBDDriver
rbd_flatten_volume_from_snapshot = false
rbd_max_clone_depth = 5
rbd_store_chunk_size = 4 
rados_connect_timeout = -1

[CINDER-BACKUP]
conf_file = /etc/cinder/cinder.conf
backup_driver = cinder.backup.drivers.ceph
backup_ceph_chunk_size = 134217728
backup_ceph_stripe_unit = 0
backup_ceph_stripe_count = 0
restore_discard_excess_bytes = true

[NOVA]
conf_file = /etc/nova/nova.conf
images_type = rbd
inject_password = false
inject_key = false
inject_partition = -2
live_migration_flag = VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE,VIR_MIGRATE_PERSIST_DEST
